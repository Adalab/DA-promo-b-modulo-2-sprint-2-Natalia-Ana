{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este momento tenemos dos fuentes de datos:\n",
    "\n",
    "1. El csv con los ataques de tiburones que hemos estado limpiando hasta ahora, el que os hemos adjuntado (attacks_limpieza_completa). Sentiros libres de usar vuestros propios csv en caso de que queráis.\n",
    "\n",
    "2. El csv con los datos climáticos de los principales paises que tienen ataques de tiburones, el que creamos en el pair programming de ayer\n",
    "\n",
    "El objetivo de la sesión de hoy será juntar en un único csv la información de ambas fuentes. \n",
    "\n",
    " - Cargaremos los dos ficheros de datos\n",
    "\n",
    " - Del dataframe de los ataques nos quedaremos solo con las filas de los países USA, AUSTRALIA, SOUTH AFRICA, NEW ZEALAND, PAPUA NEW GUINEA\n",
    "\n",
    " - Del dataframe de los datos climáticos seleccionaremos todas las columnas.\n",
    "\n",
    " - Cuando ya tengamos todos los datos deseados juntaremos los dos csv.\n",
    "\n",
    "  - Para hacer esta unión tendremos que hacer un groupby en la tabla de clima para sacar una media de las medidas climáticas por país\n",
    "\n",
    " - Antes de hacer el groupby si nos fijamos tenemos dos columnas rh_profile y wind_profile cuya información es una lista de diccionarios. Si intentamos hacer la media de eso no nos dará un valor real. A este problema ya nos enfrentamos en la clase invertida de ETL-2, donde teníais un Bonus para desempaquetar esta información. En caso de que en aquel ejercicio no lo consigierais os dejamos por aquí una posible solución que nos permite separar esa información en distintas columnas. Os dejamos el código documentado. ⚠️ Os recomendamos que vayáis desgranando el código y viendo lo que nos devuelve cada línea de código para entenderlo mejor.\n",
    "\n",
    " - # os recomendamos resetear el index del dataframe de los datos climáticos para que no se repitan los nombres de las columnas.\n",
    "\n",
    "\n",
    "# El primer problema al que nos podemos enfrentar es que si vemos los tipos de las columnas vemos que estas columnas son objetos, es decir, strings, lo que hará que trabajar con ellas sea un poco complicado: \n",
    "clima.dtypes\n",
    "\n",
    "timepoint             int64\n",
    "cloudcover            int64\n",
    "highcloud             int64\n",
    "midcloud              int64\n",
    "lowcloud              int64\n",
    "rh_profile           object\n",
    "wind_profile         object\n",
    "\n",
    "# en Python tenemos la librería `ast` que nos permite castear un string que dentro tiene diccionarios, o listas o tuplas a su tipo correspondiente. En nuestro caso, lo que conseguiremos es no tener strings sino listas en la columna. Esto lo haremos de la siguiente forma: \n",
    "\n",
    "import ast\n",
    "\n",
    "clima['wind_profile']= clima['wind_profile'].apply(ast.literal_eval)\n",
    "\n",
    "# una vez que tengamos la columna cambiada, una fantasía de Pandas es que si hago un apply sobre una columna cuyos valores son diccionarios o listas nos va a genererar una columna con los valores de los diccionarios o listas. Donde cada columna será key del diccionario o cada elemento de la lista. \n",
    "\n",
    "\n",
    "x = clima['wind_profile'].apply(pd.Series)\n",
    "\n",
    "\n",
    "# nos creamos un dataframe nuevo con el resultado de la información de una de las columnas separadas por columnas. Esto nos va a devolver un dataframe donde cada fila será una celda del dataframe anterior. \n",
    "x = df['rh_profile'].apply(pd.Series) \n",
    "\n",
    "# ¿Qué es lo que ocurre cuando hacemos esto?\n",
    "# Nos ha creado tantas columnas como valores tuvieramos en la lista. Donde columna es, en este caso, un diccionario (porque nuestra lista esta compuesta por distintos diccionarios)\n",
    "\n",
    "# Ok, hemos conseguido desempaquetar la información de la lista en distintas columnas. Ahora tenemos que despempaquetar la información de los diccionarios en distintas columnas. En este caso, lo que querremos es que las key de los diccionarios sean los nombres de las columnas y los values los valores de las celdas del dataframe. Volveremos a seguir entonces la misma lógica que antes con el apply, pero en este caso necesitamos hacerlo para todo el dataframe (que es x): \n",
    "\n",
    "# Por eso empezamos con un for para iterar por cada una de las columnas. \n",
    "for i in range(len(x.columns)): \n",
    "\n",
    "    # aplicamos el apply,extraemos el valore de la key \"layer\" y lo almacenamos en una variable que convertimos a string \n",
    "    nombre = \"rh_\" + str(x[i].apply(pd.Series)[\"layer\"][0]) \n",
    "\n",
    "    # hacemos lo mismo con una variable que se llame valores para \"guardar\" los valores de la celda\n",
    "    valores = list(x[i].apply(pd.Series)[\"rh\"] )\n",
    "\n",
    "    # usamos el método insert de los dataframes para ir añadiendo esta información a el dataframe con la información del clima. \n",
    "    df.insert(i, nombre, valores)\n",
    "\n",
    "# una vez que hayamos hecho esto para las dos columnas ya podremos hacer el gropuby para después unir toda la información. \n",
    "\n",
    " - Guardar los resultados obtenidos en un csv que usaremos en próximos ejercicios de pair programming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. El csv con los ataques de tiburones que hemos estado limpiando hasta ahora, el que os hemos adjuntado (attacks_limpieza_completa). Sentiros libres de usar vuestros propios csv en caso de que queráis.\n",
    "\n",
    "2. El csv con los datos climáticos de los principales paises que tienen ataques de tiburones, el que creamos en el pair programming de ayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.read_csv(\"../datos/attack_limpio_2.csv\", index_col= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>case_number</th>\n",
       "      <th>year</th>\n",
       "      <th>type</th>\n",
       "      <th>country</th>\n",
       "      <th>area</th>\n",
       "      <th>location</th>\n",
       "      <th>activity</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>time</th>\n",
       "      <th>species_</th>\n",
       "      <th>href</th>\n",
       "      <th>injury</th>\n",
       "      <th>date</th>\n",
       "      <th>mes</th>\n",
       "      <th>fatal_</th>\n",
       "      <th>sex2</th>\n",
       "      <th>species_tipo</th>\n",
       "      <th>edad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1800.00.00</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>SEYCHELLES</td>\n",
       "      <td>St. Anne</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a corsair's boat was overturned</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>FATAL, all onboard were killed by sharks</td>\n",
       "      <td>1800</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>y</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1797.05.28.R</td>\n",
       "      <td>1797.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dropped overboard</td>\n",
       "      <td>child</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>Reported May-28-1797</td>\n",
       "      <td>May</td>\n",
       "      <td>y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1   case_number    year        type     country      area  \\\n",
       "0             0    1800.00.00  1800.0  Unprovoked  SEYCHELLES  St. Anne   \n",
       "1             1  1797.05.28.R  1797.0  Unprovoked         NaN       NaN   \n",
       "\n",
       "  location                         activity   name  age time species_  \\\n",
       "0      NaN  a corsair's boat was overturned    NaN  NaN  NaN      NaN   \n",
       "1      NaN                Dropped overboard  child  NaN  NaN      NaN   \n",
       "\n",
       "                                                href  \\\n",
       "0  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "1  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "\n",
       "                                     injury                  date      mes  \\\n",
       "0  FATAL, all onboard were killed by sharks                  1800  UNKNOWN   \n",
       "1                                     FATAL  Reported May-28-1797      May   \n",
       "\n",
       "  fatal_ sex2 species_tipo  edad  \n",
       "0      y    F          NaN   NaN  \n",
       "1      y  NaN          NaN   NaN  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 =pd.read_csv(\"../datos/paises_meteo.csv\", index_col= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timepoint</th>\n",
       "      <th>cloudcover</th>\n",
       "      <th>highcloud</th>\n",
       "      <th>midcloud</th>\n",
       "      <th>lowcloud</th>\n",
       "      <th>rh_profile</th>\n",
       "      <th>wind_profile</th>\n",
       "      <th>temp2m</th>\n",
       "      <th>lifted_index</th>\n",
       "      <th>rh2m</th>\n",
       "      <th>msl_pressure</th>\n",
       "      <th>prec_type</th>\n",
       "      <th>prec_amount</th>\n",
       "      <th>snow_depth</th>\n",
       "      <th>wind10m.direction</th>\n",
       "      <th>wind10m.speed</th>\n",
       "      <th>latitud</th>\n",
       "      <th>longitud</th>\n",
       "      <th>pais</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>[{'layer': '950mb', 'rh': 12}, {'layer': '900m...</td>\n",
       "      <td>[{'layer': '950mb', 'direction': 235, 'speed':...</td>\n",
       "      <td>24</td>\n",
       "      <td>-1</td>\n",
       "      <td>11</td>\n",
       "      <td>1007</td>\n",
       "      <td>rain</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>290</td>\n",
       "      <td>2</td>\n",
       "      <td>39.78373</td>\n",
       "      <td>-100.445882</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>[{'layer': '950mb', 'rh': 8}, {'layer': '900mb...</td>\n",
       "      <td>[{'layer': '950mb', 'direction': 275, 'speed':...</td>\n",
       "      <td>24</td>\n",
       "      <td>-4</td>\n",
       "      <td>10</td>\n",
       "      <td>1008</td>\n",
       "      <td>rain</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>2</td>\n",
       "      <td>39.78373</td>\n",
       "      <td>-100.445882</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timepoint  cloudcover  highcloud  midcloud  lowcloud  \\\n",
       "0          3           9      -9999     -9999     -9999   \n",
       "1          6           9      -9999     -9999     -9999   \n",
       "\n",
       "                                          rh_profile  \\\n",
       "0  [{'layer': '950mb', 'rh': 12}, {'layer': '900m...   \n",
       "1  [{'layer': '950mb', 'rh': 8}, {'layer': '900mb...   \n",
       "\n",
       "                                        wind_profile  temp2m  lifted_index  \\\n",
       "0  [{'layer': '950mb', 'direction': 235, 'speed':...      24            -1   \n",
       "1  [{'layer': '950mb', 'direction': 275, 'speed':...      24            -4   \n",
       "\n",
       "   rh2m  msl_pressure prec_type  prec_amount  snow_depth  wind10m.direction  \\\n",
       "0    11          1007      rain            2           0                290   \n",
       "1    10          1008      rain            3           0                300   \n",
       "\n",
       "   wind10m.speed   latitud    longitud pais  \n",
       "0              2  39.78373 -100.445882  USA  \n",
       "1              2  39.78373 -100.445882  USA  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Del dataframe de los ataques nos quedaremos solo con las filas de los países USA, AUSTRALIA, SOUTH AFRICA, NEW ZEALAND, PAPUA NEW GUINEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paises = df[(df[\"country\"]== \"USA\") | (df[\"country\"] == \"AUSTRALIA\") | (df[\"country\"] == \"NEW ZEALAND\") | (df[\"country\"] == \"SOUTH AFRICA\") | (df[\"country\"] == \"PAPUA NEW GUINEA\")] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AUSTRALIA', 'USA', 'PAPUA NEW GUINEA', 'NEW ZEALAND',\n",
       "       'SOUTH AFRICA'], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_paises[\"country\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Del dataframe de los datos climáticos seleccionaremos todas las columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['timepoint', 'cloudcover', 'highcloud', 'midcloud', 'lowcloud',\n",
       "       'rh_profile', 'wind_profile', 'temp2m', 'lifted_index', 'rh2m',\n",
       "       'msl_pressure', 'prec_type', 'prec_amount', 'snow_depth',\n",
       "       'wind10m.direction', 'wind10m.speed', 'latitud', 'longitud', 'pais'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['USA', 'AUSTRALIA', 'SOUTH AFRICA', 'NEW ZEALAND',\n",
       "       'PAPUA NEW GUINEA'], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[\"pais\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Cuando ya tengamos todos los datos deseados juntaremos los dos csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.rename(columns={\"pais\":\"country\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['timepoint', 'cloudcover', 'highcloud', 'midcloud', 'lowcloud',\n",
       "       'rh_profile', 'wind_profile', 'temp2m', 'lifted_index', 'rh2m',\n",
       "       'msl_pressure', 'prec_type', 'prec_amount', 'snow_depth',\n",
       "       'wind10m.direction', 'wind10m.speed', 'latitud', 'longitud', 'country'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>case_number</th>\n",
       "      <th>year</th>\n",
       "      <th>type</th>\n",
       "      <th>country</th>\n",
       "      <th>area</th>\n",
       "      <th>location</th>\n",
       "      <th>activity</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>...</th>\n",
       "      <th>lifted_index</th>\n",
       "      <th>rh2m</th>\n",
       "      <th>msl_pressure</th>\n",
       "      <th>prec_type</th>\n",
       "      <th>prec_amount</th>\n",
       "      <th>snow_depth</th>\n",
       "      <th>wind10m.direction</th>\n",
       "      <th>wind10m.speed</th>\n",
       "      <th>latitud</th>\n",
       "      <th>longitud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1791.00.00</td>\n",
       "      <td>1791.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>Port Jackson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female, an Australian aboriginal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>12</td>\n",
       "      <td>1017</td>\n",
       "      <td>rain</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>3</td>\n",
       "      <td>-24.776109</td>\n",
       "      <td>134.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1791.00.00</td>\n",
       "      <td>1791.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>Port Jackson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female, an Australian aboriginal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>12</td>\n",
       "      <td>1020</td>\n",
       "      <td>rain</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>3</td>\n",
       "      <td>-24.776109</td>\n",
       "      <td>134.755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1 case_number    year        type    country             area  \\\n",
       "0             3  1791.00.00  1791.0  Unprovoked  AUSTRALIA  New South Wales   \n",
       "1             3  1791.00.00  1791.0  Unprovoked  AUSTRALIA  New South Wales   \n",
       "\n",
       "       location activity                              name  age  ...  \\\n",
       "0  Port Jackson      NaN  female, an Australian aboriginal  NaN  ...   \n",
       "1  Port Jackson      NaN  female, an Australian aboriginal  NaN  ...   \n",
       "\n",
       "  lifted_index rh2m msl_pressure prec_type prec_amount snow_depth  \\\n",
       "0           -1   12         1017      rain           2          0   \n",
       "1           -1   12         1020      rain           3          0   \n",
       "\n",
       "  wind10m.direction wind10m.speed    latitud  longitud  \n",
       "0               190             3 -24.776109   134.755  \n",
       "1               160             3 -24.776109   134.755  \n",
       "\n",
       "[2 rows x 38 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = pd.merge(left = df_paises, right= df2, how= \"left\", left_on= \"country\", right_on= \"country\")\n",
    "df_final.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AUSTRALIA', 'USA', 'PAPUA NEW GUINEA', 'NEW ZEALAND',\n",
       "       'SOUTH AFRICA'], dtype=object)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final[\"country\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ef996a58dd4038b19127a5b342ff558a720418179ddf7c29df6339888c2ae8ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
